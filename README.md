# üìö RAG-BIBUNAL: Agente Inteligente de Consulta Bibliogr√°fica con APIs de LLM

Este proyecto implementa un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** para responder preguntas acad√©micas a partir de documentos PDF de la Biblioteca de la Universidad Nacional de Colombia, Sede La Paz. Utiliza modelos de lenguaje avanzados alojados v√≠a API (Gemini, OpenAI, Groq) y realiza recuperaci√≥n sem√°ntica con embeddings y un vectorstore local (ChromaDB).

---

## üöÄ Caracter√≠sticas

- ‚úÖ Recuperaci√≥n sem√°ntica precisa desde documentos PDF
- ‚úÖ Interfaz web con **Gradio**
- ‚úÖ Selecci√≥n de LLM (Groq, OpenAI, Gemini)
- ‚úÖ Integraci√≥n con **ChromaDB**, **HuggingFace Transformers**, y m√°s
- ‚úÖ Evaluaci√≥n con m√©tricas como **Factualidad** y **Relevancia** (via [RAGAS](https://github.com/explodinggradients/ragas))

---

## üß† Tecnolog√≠as usadas

| Componente                  | Tecnolog√≠a / Herramienta         |
|----------------------------|----------------------------------|
| Embeddings                 | `sentence-transformers/all-MiniLM-L6-v2` |
| Vectorstore                | `Chroma`                         |
| Lectura de PDFs            | `PyPDFLoader` de `langchain`     |
| Divisi√≥n de texto          | `RecursiveCharacterTextSplitter`|
| LLMs (v√≠a API)             | Gemini, OpenAI, Groq (LLaMA 3)   |
| Evaluaci√≥n del sistema     | RAGAS                            |

