import time
import requests
import google.generativeai as genai
import openai
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate
import logging
import json
from datetime import datetime
import os
from dotenv import load_dotenv



# Configuraci√≥n de logging simple
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Cargar las variables del archivo .env
load_dotenv(".env", override=True)  # Si .env est√° en la misma carpeta


# Obtener las claves desde el entorno
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Configurar APIs
try:
    genai.configure(api_key=GEMINI_API_KEY)
    logger.info("‚úÖ Gemini configurado")
except Exception as e:
    logger.error(f"‚ùå Error configurando Gemini: {e}")

try:
    openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
    logger.info("‚úÖ OpenAI configurado")
except Exception as e:
    logger.error(f"‚ùå Error configurando OpenAI: {e}")

logger.info("APIs configuradas: Groq, Gemini, OpenAI")

# Variables globales
retriever = None
historial = []

# Prompt simple
prompt_template = """
**Instrucciones Generales:**
Act√∫a como un asistente experto en an√°lisis de documentos y respuestas basadas en datos. Tu objetivo es proporcionar respuestas claras, precisas, completas y bien estructuradas basadas exclusivamente en el contexto proporcionado y el historial de la conversaci√≥n. Sigue estas directrices estrictamente:

1. **Uso del Contexto y Historial:**
   - Utiliza √∫nicamente la informaci√≥n del **contexto** y el **historial** para responder.
   - Si el contexto no contiene informaci√≥n suficiente, responde: "No hay suficiente informaci√≥n en el contexto para responder esta pregunta."
   - Integra fragmentos relevantes del contexto de manera natural, cit√°ndolos o parafrase√°ndolos seg√∫n sea necesario.
   - Considera el historial para mantener coherencia en las respuestas, especialmente si la pregunta se refiere a interacciones previas.

2. **Claridad y Precisi√≥n:**
   - Responde en un lenguaje claro, profesional y adaptado al nivel de comprensi√≥n del usuario.
   - Evita jerga t√©cnica a menos que la pregunta lo requiera; en ese caso, explica los t√©rminos.
   - Si la pregunta es ambigua, identifica la ambig√ºedad y sugiere una reformulaci√≥n espec√≠fica para aclararla. Por ejemplo: "Tu pregunta podr√≠a referirse a X o Y. ¬øPodr√≠as precisar si te refieres a X o Y?"

3. **Estructura de la Respuesta:**
   - Estructura la respuesta en secciones claras (si aplica) usando encabezados como "Respuesta Principal", "Detalles Adicionales" o "Ejemplo".
   - Usa listas, vi√±etas o numeraci√≥n para mejorar la legibilidad cuando sea necesario.
   - Proporciona ejemplos concretos si la pregunta lo permite y el contexto lo soporta.
   - Si la pregunta requiere un an√°lisis profundo, divide la respuesta en pasos l√≥gicos.

4. **Manejo de Preguntas Complejas:**
   - Si la pregunta tiene m√∫ltiples partes, responde cada una por separado con un encabezado claro.
   - Si el contexto contiene informaci√≥n contradictoria, se√±ala la contradicci√≥n y ofrece la interpretaci√≥n m√°s plausible basada en los datos disponibles.
   - Para preguntas abiertas, ofrece una respuesta completa pero concisa, priorizando la informaci√≥n m√°s relevante.

5. **Tono y √âtica:**
   - Mant√©n un tono neutral, respetuoso y profesional en todo momento.
   - Evita cualquier sesgo, suposici√≥n o informaci√≥n no verificada.
   - Si la pregunta toca temas sensibles, responde con sensibilidad y enf√≥cate en hechos objetivos.

6. **Multiling√ºismo:**
   - Responde en el idioma de la pregunta (en este caso, espa√±ol) a menos que se indique lo contrario.
   - Si se solicita una traducci√≥n o respuesta en otro idioma, proporci√≥nala junto con la respuesta en espa√±ol.

7. **Formato de Salida:**
   - Usa un formato markdown claro para mejorar la legibilidad (por ejemplo, **negritas** para √©nfasis, *cursivas* para citas, o listas para puntos clave).
   - Si la respuesta es extensa, incluye un resumen inicial breve antes de los detalles.
   - Termina con una conclusi√≥n o recomendaci√≥n si la pregunta lo permite.

**Contexto:**
{context}

**Historial de Conversaci√≥n:**
{historial}

**Pregunta Actual:**
{question}

**Respuesta:**
- **Resumen**: [Proporciona un resumen breve de la respuesta, si aplica]
- **Respuesta Principal**: [Desarrollo completo de la respuesta, integrando el contexto y el historial]
- **Detalles Adicionales** (opcional): [Informaci√≥n complementaria o aclaraciones]
- **Conclusi√≥n** (opcional): [Cierre o recomendaci√≥n basada en la respuesta]

**Nota**: Si no puedes responder completamente debido a limitaciones en el contexto, explica por qu√© y sugiere c√≥mo obtener m√°s informaci√≥n.
"""

# Preguntas preestablecidas con ground truth
PREGUNTAS_Y_GROUND_TRUTH = [
    {
        "question": "¬øQu√© es Q-Learning y c√≥mo funciona?",
        "ground_truth": "Q-Learning es un algoritmo de aprendizaje por refuerzo sin modelo que aprende la funci√≥n de valor Q(s,a) que representa la recompensa esperada de tomar la acci√≥n 'a' en el estado 's' y seguir la pol√≠tica √≥ptima. Funciona mediante la actualizaci√≥n iterativa de una tabla Q usando la ecuaci√≥n Q(s,a) = Q(s,a) + Œ±[r + Œ≥ max Q(s',a') - Q(s,a)]."
    },
    {
        "question": "¬øCu√°l es la ecuaci√≥n de Bellman en Q-Learning?",
        "ground_truth": "La ecuaci√≥n de Bellman en Q-Learning es: Q(s,a) = R(s,a) + Œ≥ * max[Q(s',a')] donde Q(s,a) es el valor Q del estado s y acci√≥n a, R(s,a) es la recompensa inmediata, Œ≥ es el factor de descuento, y max[Q(s',a')] es el m√°ximo valor Q del siguiente estado s'."
    },
    {
        "question": "¬øQu√© significa la tasa de aprendizaje en Q-Learning?",
        "ground_truth": "La tasa de aprendizaje (Œ±) en Q-Learning controla qu√© tan r√°pido el agente actualiza sus valores Q. Un valor alto (cerca de 1) hace que el agente aprenda r√°pidamente pero sea inestable, mientras que un valor bajo (cerca de 0) hace el aprendizaje m√°s estable pero lento. T√≠picamente se usa Œ± entre 0.1 y 0.5."
    },
    {
        "question": "¬øCu√°l es la diferencia entre exploraci√≥n y explotaci√≥n?",
        "ground_truth": "Exploraci√≥n significa que el agente prueba acciones aleatorias para descubrir nuevas estrategias y evitar quedarse en √≥ptimos locales. Explotaci√≥n significa que el agente elige la mejor acci√≥n conocida basada en su experiencia actual. El balance entre ambas se maneja t√≠picamente con estrategias como epsilon-greedy."
    },
    {
        "question": "¬øC√≥mo se actualiza la tabla Q?",
        "ground_truth": "La tabla Q se actualiza usando la regla: Q(s,a) = Q(s,a) + Œ±[r + Œ≥ max Q(s',a') - Q(s,a)] donde Œ± es la tasa de aprendizaje, r es la recompensa recibida, Œ≥ es el factor de descuento, y el t√©rmino entre corchetes es el error temporal difference (TD)."
    },
    {
        "question": "¬øQu√© es el factor de descuento?",
        "ground_truth": "El factor de descuento (Œ≥) determina la importancia de las recompensas futuras versus las inmediatas. Un valor cercano a 0 hace que el agente sea miope (solo considera recompensas inmediatas), mientras que un valor cercano a 1 hace que considere igualmente las recompensas a largo plazo. T√≠picamente Œ≥ est√° entre 0.9 y 0.99."
    },
    {
        "question": "¬øCu√°les son las ventajas del Q-Learning?",
        "ground_truth": "Las ventajas del Q-Learning incluyen: no requiere modelo del entorno, garantiza convergencia a la pol√≠tica √≥ptima bajo ciertas condiciones, es simple de implementar, funciona con espacios de estados y acciones discretos, y puede manejar problemas estoc√°sticos."
    },
    {
        "question": "¬øEn qu√© problemas se aplica Q-Learning?",
        "ground_truth": "Q-Learning se aplica en: videojuegos (como Atari), navegaci√≥n rob√≥tica, control de tr√°fico, sistemas de recomendaci√≥n, trading financiero, optimizaci√≥n de recursos, gesti√≥n de inventarios, y cualquier problema de toma de decisiones secuencial con recompensas."
    },
    {
        "question": "¬øQu√© es la pol√≠tica epsilon-greedy?",
        "ground_truth": "La pol√≠tica epsilon-greedy es una estrategia que balancea exploraci√≥n y explotaci√≥n. Con probabilidad (1-Œµ) elige la mejor acci√≥n conocida (explotaci√≥n) y con probabilidad Œµ elige una acci√≥n aleatoria (exploraci√≥n). Œµ t√≠picamente decrece durante el entrenamiento desde ~1.0 hasta ~0.1."
    },
    {
        "question": "¬øC√≥mo se eval√∫a un agente Q-Learning?",
        "ground_truth": "Un agente Q-Learning se eval√∫a mediante: recompensa acumulada promedio por episodio, tasa de convergencia a la pol√≠tica √≥ptima, estabilidad del aprendizaje, tiempo de entrenamiento requerido, y rendimiento comparado con otros algoritmos. Tambi√©n se usan m√©tricas como la p√©rdida TD y la exploraci√≥n efectiva."
    }
]

# üìä DATOS PARA EXPORTAR JSON
datos_para_json = []

def cargar_pdf(pdf_path):
    """Cargar y procesar PDF"""
    global retriever
    
    print("üìÑ Cargando PDF...")
    
    # Cargar PDF
    loader = PyPDFLoader(pdf_path)
    docs = loader.load()
    
    # Dividir en chunks
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = splitter.split_documents(docs)
    
    # Crear embeddings y vectorstore
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = FAISS.from_documents(splits, embeddings)
    retriever = vectorstore.as_retriever(search_type="similarity")
    
    print(f"‚úÖ PDF procesado: {len(docs)} p√°ginas, {len(splits)} chunks")

def consultar_groq(prompt, max_reintentos=3):
    """Consultar API de Groq con reintentos y rate limiting"""
    for intento in range(max_reintentos):
        try:
            url = "https://api.groq.com/openai/v1/chat/completions"
            headers = {"Authorization": f"Bearer {GROQ_API_KEY}", "Content-Type": "application/json"}
            body = {
                "model": "llama3-70b-8192",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1000
            }
            
            response = requests.post(url, headers=headers, json=body, timeout=30)
            
            # Si es rate limit (429), espera m√°s tiempo
            if response.status_code == 429:
                tiempo_espera = (intento + 1) * 10  # 10, 20, 30 segundos
                print(f"‚è≥ Rate limit alcanzado. Esperando {tiempo_espera} segundos...")
                time.sleep(tiempo_espera)
                continue
            
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
            
        except requests.exceptions.RequestException as e:
            if intento < max_reintentos - 1:
                tiempo_espera = (intento + 1) * 5  # 5, 10 segundos
                print(f"‚ö†Ô∏è Error en intento {intento + 1}. Reintentando en {tiempo_espera}s...")
                time.sleep(tiempo_espera)
            else:
                return f"‚ùå Error Groq despu√©s de {max_reintentos} intentos: {str(e)[:100]}"
        except Exception as e:
            return f"‚ùå Error Groq: {str(e)[:100]}"
    
    return "‚ùå Error Groq: M√°ximo de reintentos alcanzado"

def consultar_gemini(prompt):
    """Consultar API de Gemini"""
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"‚ùå Error Gemini: {str(e)[:100]}"

def consultar_openai(prompt):
    """Consultar API de OpenAI"""
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ùå Error OpenAI: {str(e)[:100]}"

def hacer_pregunta_json(pregunta_data, modelo="groq"):
    """Hacer una pregunta al sistema RAG y recopilar datos para JSON"""
    global retriever, historial, datos_para_json
    
    if not retriever:
        return {"error": "PDF no cargado"}
    
    pregunta = pregunta_data["question"]
    ground_truth = pregunta_data["ground_truth"]
    
    # Obtener contexto relevante (documentos recuperados)
    docs = retriever.get_relevant_documents(pregunta)
    contexts = [doc.page_content for doc in docs[:3]]  # Top 3 documentos m√°s relevantes
    
    # Preparar prompt
    historial_str = "\n".join([f"P: {p}\nR: {r[:100]}..." for p, r in historial[-3:]])
    prompt = prompt_template.format(
        context="\n".join(contexts[:2000]),  # Limitar contexto
        historial=historial_str,
        question=pregunta
    )
    
    # Obtener respuesta del modelo especificado
    if modelo == "groq":
        respuesta = consultar_groq(prompt)
    elif modelo == "gemini":
        respuesta = consultar_gemini(prompt)
    elif modelo == "openai":
        respuesta = consultar_openai(prompt)
    else:
        respuesta = consultar_groq(prompt)  # Default
    
    # Limpiar respuesta si hay error
    if respuesta.startswith("‚ùå"):
        respuesta = "Error en la consulta al modelo"
    
    # Crear objeto para JSON
    pregunta_objeto = {
        "id": len(datos_para_json) + 1,
        "question": pregunta,
        "contexts": contexts,
        "answer": respuesta,
        "ground_truth": ground_truth,
        "modelo": modelo,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "metadata": {
            "num_contextos": len(contexts),
            "longitud_respuesta": len(respuesta),
            "longitud_pregunta": len(pregunta)
        }
    }
    
    # Agregar a datos para JSON
    datos_para_json.append(pregunta_objeto)
    
    # Guardar en historial
    historial.append((pregunta, respuesta[:200]))
    if len(historial) > 5:
        historial.pop(0)
    
    return {
        "pregunta": pregunta,
        "contextos": contexts,
        "respuesta": respuesta,
        "ground_truth": ground_truth
    }

def exportar_json(filename="respuestas_rag.json", modelo="groq"):
    """Exportar datos al formato JSON"""
    
    if not datos_para_json:
        print("‚ùå No hay datos para exportar")
        return
    
    # Filtrar por modelo si se especifica
    if modelo != "todos":
        datos_filtrados = [d for d in datos_para_json if d["modelo"] == modelo]
    else:
        datos_filtrados = datos_para_json
    
    if not datos_filtrados:
        print(f"‚ùå No hay datos para el modelo {modelo}")
        return
    
    # Crear estructura JSON completa
    datos_json = {
        "metadata": {
            "total_preguntas": len(datos_filtrados),
            "modelos_usados": list(set([d["modelo"] for d in datos_filtrados])),
            "fecha_exportacion": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "version": "1.0"
        },
        "preguntas_y_respuestas": datos_filtrados
    }
    
    # Guardar JSON
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(datos_json, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Datos exportados a {filename}")
        print(f"üìä Registros exportados: {len(datos_filtrados)}")
        print(f"ü§ñ Modelo(s) usado(s): {', '.join(datos_json['metadata']['modelos_usados'])}")
        
        return datos_json
        
    except Exception as e:
        print(f"‚ùå Error al exportar JSON: {str(e)}")
        return None

def ejecutar_preguntas_json(modelo="groq"):
    """Ejecutar las 10 preguntas y recopilar datos para JSON"""
    print(f"\nüß† Ejecutando 10 preguntas con modelo: {modelo.upper()}")
    print("=" * 60)
    
    resultados_totales = []
    
    for i, pregunta_data in enumerate(PREGUNTAS_Y_GROUND_TRUTH, 1):
        print(f"\n‚è≥ Procesando pregunta {i}/10...")
        print(f"‚ùì {pregunta_data['question']}")
        
        # Hacer pregunta
        resultado = hacer_pregunta_json(pregunta_data, modelo)
        
        if "error" in resultado:
            print(f"‚ùå {resultado['error']}")
            continue
        
        # Mostrar respuesta resumida
        respuesta_corta = resultado["respuesta"][:200] + "..." if len(resultado["respuesta"]) > 200 else resultado["respuesta"]
        print(f"ü§ñ Respuesta: {respuesta_corta}")
        
        resultados_totales.append(resultado)
        
        # Pausa entre preguntas
        time.sleep(1)
    
    return resultados_totales

def mostrar_resumen():
    """Mostrar resumen de datos recopilados"""
    print(f"\n{'='*60}")
    print("üìä RESUMEN DE DATOS RECOPILADOS")
    print('='*60)
    print(f"‚úÖ Total de registros: {len(datos_para_json)}")
    
    if datos_para_json:
        modelos = set([d["modelo"] for d in datos_para_json])
        print(f"ü§ñ Modelos usados: {', '.join(modelos)}")
        print(f"üìù Preguntas √∫nicas: {len(set([d['question'] for d in datos_para_json]))}")
        print(f"üìÑ Promedio de contextos por pregunta: {sum([d['metadata']['num_contextos'] for d in datos_para_json]) / len(datos_para_json):.1f}")

def main():
    """Funci√≥n principal"""
    print("üß† Sistema RAG con Exportaci√≥n JSON")
    print("=" * 60)
    
    # Cargar PDF
    pdf_path = "docs/PDF_IA.pdf"
    
    try:
        cargar_pdf(pdf_path)
        
        # Seleccionar modelo
        print("\nü§ñ Selecciona el modelo a usar:")
        print("1. Groq (llama3-70b-8192)")
        print("2. Gemini (gemini-1.5-flash)")
        print("3. OpenAI (gpt-3.5-turbo)")
        print("4. Todos los modelos")
        
        opcion = input("\nüéØ Opci√≥n (1-4, default=1): ").strip()
        
        modelos_map = {
            "1": "groq",
            "2": "gemini", 
            "3": "openai",
            "4": "todos"
        }
        
        modelo_seleccionado = modelos_map.get(opcion, "groq")
        
        if modelo_seleccionado == "todos":
            # Ejecutar con todos los modelos
            for modelo in ["groq", "gemini", "openai"]:
                print(f"\nüöÄ Ejecutando con {modelo.upper()}...")
                ejecutar_preguntas_json(modelo)
        else:
            # Ejecutar con modelo seleccionado
            ejecutar_preguntas_json(modelo_seleccionado)
        
        # Mostrar resumen
        mostrar_resumen()
        
        # Exportar JSON
        print(f"\nüíæ ¬øExportar datos a JSON?")
        exportar = input("üìù (s/n, default=s): ").strip().lower()
        
        if exportar in ['', 's', 'si', 'y', 'yes']:
            if modelo_seleccionado == "todos":
                # Exportar por modelo
                for modelo in ["groq", "gemini", "openai"]:
                    filename = f"respuestas_rag_{modelo}1.json"
                    exportar_json(filename, modelo)
                
                # Exportar todos juntos
                exportar_json("respuestas_rag_todos.json", "todos")
            else:
                filename = f"respuestas_rag_{modelo_seleccionado}.json"
                exportar_json(filename, modelo_seleccionado)
        
        print(f"\nüéâ ¬°Proceso completado!")
        print(f"üìÅ Archivos JSON listos con todas las respuestas")
        
    except FileNotFoundError:
        print("‚ùå Error: No se encontr√≥ 'docs/PDF_IA.pdf'")
        print("üí° Coloca tu PDF en la carpeta 'docs/' con el nombre 'PDF_IA.pdf'")
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")

if __name__ == "__main__":
    main()